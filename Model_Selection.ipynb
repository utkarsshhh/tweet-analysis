{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2e5f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/utkarshpadia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8574db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset for training the model\n",
    "tweets_data = pd.read_csv(\"Twitter_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9079ec0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b557015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data['category'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ce6eef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data['clean_text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a4e33e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data['category'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "225a9b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162980, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "106e8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data.dropna(axis =0 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25f960ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data['category'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "28ea847c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data['clean_text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d3ed5a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162969, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4030861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_data['clean_text']\n",
    "Y = tweets_data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49f4904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size = 0.3,random_state = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61f64928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the tweets\n",
    "def tokenize(text):\n",
    "    '''\n",
    "    \n",
    "    This function processes the text by removing stopwords, tokenizing the sentences and lemmatizing words to \n",
    "    make the text usable for further transformation \n",
    "    \n",
    "    Input:\n",
    "    text - a string(tweet) which is the input of the model\n",
    "    \n",
    "    Output:\n",
    "    returns the input text as clean tokens in a list\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenized_text = [lemmatizer.lemmatize(token).strip() for token in tokens]\n",
    "    return tokenized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "490675f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the pipeline for transforming the data and classifying it \n",
    "nlp_pipeline = Pipeline([('vect',CountVectorizer(tokenizer = tokenize)),\n",
    "                        ('tran',TfidfTransformer()),\n",
    "                        ('clf',RandomForestClassifier())])\n",
    "#training the pipeline\n",
    "nlp_pipeline.fit(x_train,y_train)\n",
    "#making predictions on the test data\n",
    "y_pred = nlp_pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52f99d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0] == y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7dcd55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse the accuracy of the model\n",
    "def check_accuracy(pred_values,real_values):\n",
    "    '''\n",
    "    \n",
    "    This function checks the accuracy by comparing the pred_values and real_values\n",
    "    \n",
    "    Input:\n",
    "    pred_values - array of predicted classification values from the pipeline\n",
    "    real_values - array of the actual classification values of the input\n",
    "    \n",
    "    Output:\n",
    "    The function doesn't return anything but prints the comparison results\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(classification_report(real_values, pred_values))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cf6fd085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.89      0.58      0.70     10678\n",
      "         0.0       0.83      0.91      0.87     16657\n",
      "         1.0       0.81      0.89      0.85     21556\n",
      "\n",
      "    accuracy                           0.83     48891\n",
      "   macro avg       0.84      0.79      0.81     48891\n",
      "weighted avg       0.84      0.83      0.82     48891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysing the accuracy of nlp_pipeline model\n",
    "check_accuracy(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "734b0efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysing parameters to improve the accuracy\n",
    "RandomForestClassifier().get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5740b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining hyperparameters for tuning\n",
    "parameters = {\n",
    "    'clf__criterion':['gini', 'entropy'],\n",
    "    'clf__max_features':['sqrt','log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f5371df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/utkarshpadia/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.82596117 0.75288836 0.82769681 0.75443117        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Defining the pipeline and tuned model\n",
    "nlp_pipeline = Pipeline([('vect',CountVectorizer(tokenizer = tokenize)),\n",
    "                        ('tran',TfidfTransformer()),\n",
    "                        ('clf',RandomForestClassifier())])\n",
    "tuned_model = GridSearchCV(nlp_pipeline,parameters,n_jobs=1)\n",
    "tuned_model.fit(x_train,y_train)\n",
    "y_pred_tuned = tuned_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b61f3a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.89      0.58      0.70     10678\n",
      "         0.0       0.83      0.92      0.87     16657\n",
      "         1.0       0.82      0.89      0.85     21556\n",
      "\n",
      "    accuracy                           0.83     48891\n",
      "   macro avg       0.84      0.80      0.81     48891\n",
      "weighted avg       0.84      0.83      0.83     48891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(y_pred_tuned,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd2c0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model as a pickle file\n",
    "pickle.dump(tuned_model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942199e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
